---
title: "P8105 Homework 6"
output: github_document
date: "December 3rd, 2022"
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  warning = FALSE, 
  message = FALSE,
  fig.dim = c(12, 7))

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Part 1: Central Park Weather Data

For this problem, we’ll use the 2017 Central Park weather data from the `rnoaa` package. The code chunk below will download these data.

```{r load noaa}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
crossval_df = weather_df %>% 
  modelr::bootstrap(n = 100) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  group_by(term) %>% 
  summarize(boot_se = sd(estimate))
```

## Part 2: Washington Post Homicide Data

### Load and clean data

The Washington Post has gathered data on homicides in 50 large U.S. cities. Let's load the raw homicide data and inspect it.

```{r load homicide data}
homicide_data = read_csv("data/homicide-data.csv") %>% 
  janitor::clean_names()
homicide_data
```

There are `r nrow(homicide_data)` observations of `r ncol(homicide_data)` variables containing information about homicides in 50 cities across the US. The data contains the date, victim information (name, age, sex, race), location (city, state, latitude, longitude), and status of the case.

Next, let's tidy the data by creating a `city_state` variable, and omitting Dallas, Phoenix, Kansas City, and Tulsa, AL (a data entry error). We will also convert `victim_age` to a numeric variable, and keep observations only where the victim's race is White or Black.

```{r clean data}
homicide_data = homicide_data %>% 
  mutate(
    state = str_to_upper(state),
    city_state = str_c(city, state, sep = ", "), 
    victim_age = as.numeric(victim_age),
    resolved = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(city_state != "Dallas, TX" & 
           city_state != "Phoenix, AZ" & 
           city_state != "Kansas City, MO" & 
           city_state != "Tulsa, AL", 
         victim_race == "White" | victim_race == "Black")
```

There are now `r nrow(homicide_data)` observations of `r ncol(homicide_data)` variables in our cleaned dataset containing information about homicides in 47 cities across the US.

### Modelling homicide data

Now run `glm` for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r map glm}
homicide_data %>% 
  nest(data = -city_state) %>% 
  mutate(models = map(data, ~ glm(resolved ~ victim_age + victim_sex + victim_race, 
                                 data = ., family = "binomial")), 
         results = map(models, broom::tidy)) %>% 
  select(-data, -models) %>% 
  unnest(results) %>% 
  mutate(OR = exp(estimate)) %>%
  select(city_state, term, log_OR = estimate, OR, p.value) 

```




