---
title: "P8105 Homework 6"
output: github_document
date: "December 3rd, 2022"
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(patchwork)

knitr::opts_chunk$set(
  warning = FALSE, 
  message = FALSE,
  fig.dim = c(12, 7))

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Part 1: Central Park Weather Data

For this problem, we’ll use the 2017 Central Park weather data from the `rnoaa` package. The code chunk below will download these data.

```{r load noaa}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
crossval_df = weather_df %>% 
  modelr::bootstrap(n = 100) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  group_by(term) %>% 
  summarize(boot_se = sd(estimate))
```

## Part 2: Washington Post Homicide Data

### Load and clean data

The Washington Post has gathered data on homicides in 50 large U.S. cities. Let's load the raw homicide data and inspect it.

```{r load homicide data}
homicide_data = read_csv("data/homicide-data.csv") %>% 
  janitor::clean_names()
homicide_data
```

There are `r nrow(homicide_data)` observations of `r ncol(homicide_data)` variables containing information about homicides in 50 cities across the US. The data contains the date, victim information (name, age, sex, race), location (city, state, latitude, longitude), and status of the case.

Next, let's tidy the data by creating a `city_state` variable, and omitting Dallas, Phoenix, Kansas City, and Tulsa, AL (a data entry error). We will also convert `victim_age` to a numeric variable, and keep observations only where the victim's race is White or Black.

```{r clean data}
homicide_data = homicide_data %>% 
  mutate(
    state = str_to_upper(state),
    city_state = str_c(city, state, sep = ", "), 
    victim_age = as.numeric(victim_age),
    resolved = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(city_state != "Dallas, TX" & 
           city_state != "Phoenix, AZ" & 
           city_state != "Kansas City, MO" & 
           city_state != "Tulsa, AL", 
         victim_race == "White" | victim_race == "Black")
```

There are now `r nrow(homicide_data)` observations of `r ncol(homicide_data)` variables in our cleaned dataset containing information about homicides in 47 cities across the US.

### Modelling homicide data

Now, using purrr::map, list columns, and unnest, we will run `glm` for each of the cities in the dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. 

The resulting code creates a dataframe with estimated adjusted ORs and 95% CIs for each city, comparing the odds of solving a homicide among male victims compared to females.

```{r map glm}
OR_df = homicide_data %>% 
  nest(data = -city_state) %>% 
  mutate(models = map(data, ~ glm(resolved ~ victim_age + victim_sex + victim_race, 
                                 data = ., family = "binomial")), 
         results = map(models, broom::tidy)) %>% 
  select(-data, -models) %>% 
  unnest(results) %>% 
  mutate(OR = exp(estimate),
         CIL = exp(estimate - 1.96*std.error),
         CIU = exp(estimate + 1.96*std.error)) %>% 
  filter(term == "victim_sexMale") %>% 
  select(city_state, term, log_OR = estimate, OR, CIL, CIU, p.value)
```

Next, we will plot the estimated ORs and CIs for each city.

```{r plot ORs}
OR_df %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR, colour = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CIL, ymax = CIU, width = .3)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1), 
        legend.position = "none") + 
  labs(
    x = "Location",
    y = "Adjusted odds ratio",
    title = "Effect of male vs. female victim sex on the odds of solving homicides across major U.S. cities, 2007-2017",
    caption = paste0(
          "Error bars represent the 95% confidence interval.",
          "\nSource: The Washington Post."))
```

We can see that across a majority of cities, the ORs are less than 1, indicating a decreased odds of resolving a homicide when the victim is male vs. female. This effect is the greatest for New York, Baton Rouge, and Omaha. Many cities also have a non-significant association between victim sex and resolving homicides, indicated by the 95% CI for the adjusted OR crossing the null value of 1. 

On the other hand, there is an increased odds of solving a homicide when the victim is male vs. female in Albequerque, Stockton, and Fresno. However, for the 3 cities with the highest adjusted ORs, the 95% CI crosses the null value of 1, indicating there may be a high variability in these estimates rather than an effect of victim sex on solving homicides.

## Part 3: Child Birthweight

Next, we will analyze data gathered to understand the effects of several variables on a child’s birthweight. This dataset consists of roughly 4000 children and includes variables related to the baby's sex, age, body measurements, maternal health, and parents' socioeconomic information.

### Load and clean data

The code chunk below loads and clean the data for regression analysis. We will convert numeric variables into factor variables for categorical variables `babysex`, `frace`, `malform`, and `mrace`.

```{r load birth data}
birthweight_df = read_csv("data/birthweight.csv") %>% 
  janitor::clean_names()

birthweight_df = birthweight_df %>% 
  mutate(babysex = as.factor(babysex), 
         frace = as.factor(frace), 
         malform = as.factor(malform), 
         mrace = as.factor(mrace), 
         id = 1:nrow(birthweight_df))

```

### Proposing a model for birthweight

First, we want to propose our own model for birthweight based on variables in the dataset. I will start with selecting underlying factors that I think predict birthweight. For this, I will include gestational age, head circumference, length of the baby, mother's weight at delivery because I think they are important biological variables which determine birthweight. 

```{r}
model_1 = lm(bwt ~ bhead + blength + gaweeks + delwt, data = birthweight_df) 
summary(model_1) 
```

Examining `summary(model_1)` output, we can see coefficient estimates for each variable in our linear model, and see that the p-value of the Wald test for each variable is less than 0.05, indicating that they are all significantly associated with our outcome. Moreover, we can see the model fit is decent, with an $R^2$ value of 0.695, indicating the selected variables explain 69.5% of the variability in birthweight. 

However, we may want to see how certain sociodemographic variables predict birthweight. Therefore, to start, I will add maternal and paternal race, cigarettes smoken, family income to the model.

```{r}
model_2 = lm(formula = bwt ~ babysex + bhead + blength + delwt + 
               mrace + frace + smoken + fincome, data = birthweight_df)
summary(model_2) 
```

Examining `summary(model_2)` output, we can see the model fit has improved, with an $R^2$ value that indicates the selected variables explain 71.05% of the variability in birthweight. However, we can see coefficient estimates for the `frace` variable are insignificant, and the coefficient for `fincome` is near-zero, with a p-value of 0.045 that approaches significance. Therefore, we will omit these two variables.

```{r}
model_3 = lm(bwt ~ bhead + blength + gaweeks + delwt + smoken + mrace, data = birthweight_df) 
summary(model_3) 
```

After removing `frace` and `fincome`, we can see the model fit has actually improved, with an $R^2$ value that indicates the selected variables explain 71.37% of the variability in birthweight. The output of `summary(model_3)` shows all variables are significantly associated with birthweight, when adjusting for the other variables. Notably, we see `mrace` is a more significant predictor of birthweight, suggesting there were perhaps too many covariates that lead to multicolinearity in Model 2. Therefore, we will keep `model_3` as our final model.

Finally, we want to assess model fit and check key assumptions, by plotting the residuals and fitted values using `add_residuals` and `add_predictions`

```{r}
birthweight_df = birthweight_df %>% 
  modelr::add_residuals(model_3) %>% 
  modelr::add_predictions(model_3) 

resid_plot = birthweight_df %>% 
  ggplot(aes(x = id, y = resid)) + geom_point(alpha = 0.5, size = 0.5) + 
  labs(
    title = "Residuals for birthweight regression model",
    x = "",
    y = "Residual")

pred_plot = birthweight_df %>% 
  ggplot(aes(x = id, y = pred)) + geom_point(alpha = 0.5, size = 0.5) + 
  labs(
    title = "Predicted values for birthweight regression model",
    x = "",
    y = "Predicted value (birthweight)")

resid_plot + pred_plot
```


### Cross-validating models

Now, we want to compare our model to a small model, using length at birth and gestational age as predictors (main effects only) and a large model, using head circumference, length, sex, and all interactions (including the three-way interaction). We will save Model 3 we created in the previous section as `my_mod` and fit the small and large models.

```{r}
my_mod = lm(bwt ~ bhead + blength + gaweeks + delwt + smoken + mrace, data = birthweight_df) 
small_mod = lm(bwt ~ gaweeks + blength, data = birthweight_df)
large_mod = lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = birthweight_df)
```


```{r}
cv_df =
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = cv_df %>% 
  mutate(
    my_mod = map(train, ~lm(bwt ~ bhead + blength + gaweeks + delwt + smoken + mrace, data = .x)),
    small_mod = map(train, ~lm(bwt ~ gaweeks + blength, data = .x)),
    large_mod  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(
    rmse_my = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
    rmse_small = map2_dbl(small_mod, test, ~rmse(model = .x, data = .y)),
    rmse_large = map2_dbl(large_mod, test, ~rmse(model = .x, data = .y)))
```

```{r plot rmse}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

